{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Como usar a `Embedding` layer do Keras\n",
    "- Fonte: https://www.kaggle.com/rajmehra03/a-detailed-explanation-of-keras-embedding-layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.text import one_hot, Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Embedding, Input\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corp = [\n",
    "    'tenis rainha preto',\n",
    "    'tenis rainha branco',\n",
    "    'tenis nike verde',\n",
    "    'tenis nike preto',\n",
    "    'tenis nike branco',\n",
    "    'tenis samurai adidas verde',\n",
    "    'tenis adidas preto',\n",
    "    'tenis adidas branco'\n",
    "]\n",
    "no_docs = len(corp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codificando cada palavra única\n",
    "Cada palavra dos documentos acima possuem um ID único"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O encoding para o documento  1  é  [14, 20, 25]\n",
      "O encoding para o documento  2  é  [14, 20, 45]\n",
      "O encoding para o documento  3  é  [14, 36, 4]\n",
      "O encoding para o documento  4  é  [14, 36, 25]\n",
      "O encoding para o documento  5  é  [14, 36, 45]\n",
      "O encoding para o documento  6  é  [14, 17, 16, 4]\n",
      "O encoding para o documento  7  é  [14, 16, 25]\n",
      "O encoding para o documento  8  é  [14, 16, 45]\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 50 \n",
    "encod_corp = []\n",
    "for i, doc in enumerate(corp):\n",
    "    encod_corp.append(one_hot(doc, 50))\n",
    "    print(\"O encoding para o documento \", i + 1, \" é \", one_hot(doc, 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Buscando a palavra com o maior cumprimento\n",
    "É feito um `for` para que a frase com maior cumprimento seja selecionada, para que possamos fazer o `padding`, ou seja, deixar todas as frases com a mesma quantidade de palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O maior número de palavras dentre todos os documentos é  4\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# Baixar apenas se necessário\n",
    "# nltk.download('punkt')\n",
    "\n",
    "maxlen = -1\n",
    "for doc in corp:\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "    if(maxlen < len(tokens)):\n",
    "        maxlen = len(tokens)\n",
    "\n",
    "print(\"O maior número de palavras dentre todos os documentos é \", maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No de documentos ajustados  8\n"
     ]
    }
   ],
   "source": [
    "pad_corp = pad_sequences(encod_corp, maxlen=maxlen, padding='post', value=0.0)\n",
    "print(\"No de documentos ajustados \",len(pad_corp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O encoding após o padding do documento  1  é  [14 20 25  0]\n",
      "O encoding após o padding do documento  2  é  [14 20 45  0]\n",
      "O encoding após o padding do documento  3  é  [14 36  4  0]\n",
      "O encoding após o padding do documento  4  é  [14 36 25  0]\n",
      "O encoding após o padding do documento  5  é  [14 36 45  0]\n",
      "O encoding após o padding do documento  6  é  [14 17 16  4]\n",
      "O encoding após o padding do documento  7  é  [14 16 25  0]\n",
      "O encoding após o padding do documento  8  é  [14 16 45  0]\n"
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate(pad_corp):\n",
    "     print(\"O encoding após o padding do documento \", i + 1, \" é \", doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando a camada de `Embedding`\n",
    "Agora todos os documentos têm o mesmo comprimento (após `padding`). E agora estamos prontos para criar e usar os embeddings.\n",
    "\n",
    "Vou incorporar as palavras em vetores de 8 dimensões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# especificando a input shape\n",
    "input = Input(shape=(no_docs, maxlen), dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "input shape\n",
    "cada documento possui 4 elementos ou palavras, valor este armazenado na variável maxlen\n",
    "'''\n",
    "word_input = Input(shape=(maxlen,), dtype='float64')  \n",
    "\n",
    "# criando a camada de Embedding\n",
    "word_embedding = Embedding(input_dim=vocab_size, output_dim=8, input_length=maxlen)(word_input)\n",
    "\n",
    "word_vec = Flatten()(word_embedding) # flatten\n",
    "embed_model = Model([word_input], word_vec) # unindo tudo em um model Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parâmetros da camada de `Embedding`\n",
    "\n",
    "`input_dim` = o tamanho do vocabulário que escolheremos. Em outras palavras, é o número de palavras únicas no vocabulário.\n",
    "\n",
    "`output_dim` = o número de dimensões que desejamos incorporar. Cada palavra será representada por um vetor desta dimensão.\n",
    "\n",
    "`input_length` = comprimento do máximo dos documentos, que é armazenado na variável maxlen em nosso caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model.compile(optimizer=keras.optimizers.Adam(lr=1e-3), loss='binary_crossentropy', metrics=['acc']) \n",
    "# compilando o model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "Tensor(\"embedding_1/embedding_lookup/Identity_2:0\", shape=(None, 4, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(type(word_embedding))\n",
    "print(word_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 4, 8)              400       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32)                0         \n",
      "=================================================================\n",
      "Total params: 400\n",
      "Trainable params: 400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(embed_model.summary()) # summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=embed_model.predict(pad_corp) # finally getting the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape dos Embeddings:  (8, 32)\n",
      "[[-0.00548886 -0.03592169 -0.04380827 -0.03811025 -0.04731432 -0.00550474\n",
      "  -0.02236625  0.0459923   0.04638492 -0.00064833 -0.0301376   0.0405165\n",
      "   0.01600995  0.029288   -0.02455816  0.04661772 -0.00184004 -0.03448504\n",
      "   0.02520813  0.0427362   0.02878145 -0.02024512 -0.02827085  0.04391212\n",
      "  -0.02570124  0.03301226  0.00364808 -0.03380039  0.03013071  0.03675773\n",
      "   0.00792041 -0.04911968]\n",
      " [-0.00548886 -0.03592169 -0.04380827 -0.03811025 -0.04731432 -0.00550474\n",
      "  -0.02236625  0.0459923   0.04638492 -0.00064833 -0.0301376   0.0405165\n",
      "   0.01600995  0.029288   -0.02455816  0.04661772 -0.04863527 -0.01664423\n",
      "   0.03288651 -0.01750059  0.00012063  0.00699423 -0.02460462 -0.01855447\n",
      "  -0.02570124  0.03301226  0.00364808 -0.03380039  0.03013071  0.03675773\n",
      "   0.00792041 -0.04911968]\n",
      " [-0.00548886 -0.03592169 -0.04380827 -0.03811025 -0.04731432 -0.00550474\n",
      "  -0.02236625  0.0459923   0.03480581  0.01236982 -0.00646875 -0.03116666\n",
      "  -0.04103081  0.0468041   0.04265824 -0.01098816 -0.0319088  -0.03847919\n",
      "   0.00867068 -0.03605264 -0.04605315  0.02373978 -0.01911396 -0.03347591\n",
      "  -0.02570124  0.03301226  0.00364808 -0.03380039  0.03013071  0.03675773\n",
      "   0.00792041 -0.04911968]\n",
      " [-0.00548886 -0.03592169 -0.04380827 -0.03811025 -0.04731432 -0.00550474\n",
      "  -0.02236625  0.0459923   0.03480581  0.01236982 -0.00646875 -0.03116666\n",
      "  -0.04103081  0.0468041   0.04265824 -0.01098816 -0.00184004 -0.03448504\n",
      "   0.02520813  0.0427362   0.02878145 -0.02024512 -0.02827085  0.04391212\n",
      "  -0.02570124  0.03301226  0.00364808 -0.03380039  0.03013071  0.03675773\n",
      "   0.00792041 -0.04911968]\n",
      " [-0.00548886 -0.03592169 -0.04380827 -0.03811025 -0.04731432 -0.00550474\n",
      "  -0.02236625  0.0459923   0.03480581  0.01236982 -0.00646875 -0.03116666\n",
      "  -0.04103081  0.0468041   0.04265824 -0.01098816 -0.04863527 -0.01664423\n",
      "   0.03288651 -0.01750059  0.00012063  0.00699423 -0.02460462 -0.01855447\n",
      "  -0.02570124  0.03301226  0.00364808 -0.03380039  0.03013071  0.03675773\n",
      "   0.00792041 -0.04911968]\n",
      " [-0.00548886 -0.03592169 -0.04380827 -0.03811025 -0.04731432 -0.00550474\n",
      "  -0.02236625  0.0459923   0.02352202  0.01905927  0.02116759 -0.04492472\n",
      "   0.00114735 -0.01074374 -0.03446828  0.04657385 -0.00521493 -0.02499979\n",
      "   0.0411833  -0.04705396 -0.03437755 -0.03328681  0.04742551 -0.04182632\n",
      "  -0.0319088  -0.03847919  0.00867068 -0.03605264 -0.04605315  0.02373978\n",
      "  -0.01911396 -0.03347591]\n",
      " [-0.00548886 -0.03592169 -0.04380827 -0.03811025 -0.04731432 -0.00550474\n",
      "  -0.02236625  0.0459923  -0.00521493 -0.02499979  0.0411833  -0.04705396\n",
      "  -0.03437755 -0.03328681  0.04742551 -0.04182632 -0.00184004 -0.03448504\n",
      "   0.02520813  0.0427362   0.02878145 -0.02024512 -0.02827085  0.04391212\n",
      "  -0.02570124  0.03301226  0.00364808 -0.03380039  0.03013071  0.03675773\n",
      "   0.00792041 -0.04911968]\n",
      " [-0.00548886 -0.03592169 -0.04380827 -0.03811025 -0.04731432 -0.00550474\n",
      "  -0.02236625  0.0459923  -0.00521493 -0.02499979  0.0411833  -0.04705396\n",
      "  -0.03437755 -0.03328681  0.04742551 -0.04182632 -0.04863527 -0.01664423\n",
      "   0.03288651 -0.01750059  0.00012063  0.00699423 -0.02460462 -0.01855447\n",
      "  -0.02570124  0.03301226  0.00364808 -0.03380039  0.03013071  0.03675773\n",
      "   0.00792041 -0.04911968]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape dos Embeddings: \",embeddings.shape)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of embeddings :  (8, 4, 8)\n",
      "[[[-0.00548886 -0.03592169 -0.04380827 -0.03811025 -0.04731432\n",
      "   -0.00550474 -0.02236625  0.0459923 ]\n",
      "  [ 0.04638492 -0.00064833 -0.0301376   0.0405165   0.01600995\n",
      "    0.029288   -0.02455816  0.04661772]\n",
      "  [-0.00184004 -0.03448504  0.02520813  0.0427362   0.02878145\n",
      "   -0.02024512 -0.02827085  0.04391212]\n",
      "  [-0.02570124  0.03301226  0.00364808 -0.03380039  0.03013071\n",
      "    0.03675773  0.00792041 -0.04911968]]\n",
      "\n",
      " [[-0.00548886 -0.03592169 -0.04380827 -0.03811025 -0.04731432\n",
      "   -0.00550474 -0.02236625  0.0459923 ]\n",
      "  [ 0.04638492 -0.00064833 -0.0301376   0.0405165   0.01600995\n",
      "    0.029288   -0.02455816  0.04661772]\n",
      "  [-0.04863527 -0.01664423  0.03288651 -0.01750059  0.00012063\n",
      "    0.00699423 -0.02460462 -0.01855447]\n",
      "  [-0.02570124  0.03301226  0.00364808 -0.03380039  0.03013071\n",
      "    0.03675773  0.00792041 -0.04911968]]\n",
      "\n",
      " [[-0.00548886 -0.03592169 -0.04380827 -0.03811025 -0.04731432\n",
      "   -0.00550474 -0.02236625  0.0459923 ]\n",
      "  [ 0.03480581  0.01236982 -0.00646875 -0.03116666 -0.04103081\n",
      "    0.0468041   0.04265824 -0.01098816]\n",
      "  [-0.0319088  -0.03847919  0.00867068 -0.03605264 -0.04605315\n",
      "    0.02373978 -0.01911396 -0.03347591]\n",
      "  [-0.02570124  0.03301226  0.00364808 -0.03380039  0.03013071\n",
      "    0.03675773  0.00792041 -0.04911968]]\n",
      "\n",
      " [[-0.00548886 -0.03592169 -0.04380827 -0.03811025 -0.04731432\n",
      "   -0.00550474 -0.02236625  0.0459923 ]\n",
      "  [ 0.03480581  0.01236982 -0.00646875 -0.03116666 -0.04103081\n",
      "    0.0468041   0.04265824 -0.01098816]\n",
      "  [-0.00184004 -0.03448504  0.02520813  0.0427362   0.02878145\n",
      "   -0.02024512 -0.02827085  0.04391212]\n",
      "  [-0.02570124  0.03301226  0.00364808 -0.03380039  0.03013071\n",
      "    0.03675773  0.00792041 -0.04911968]]\n",
      "\n",
      " [[-0.00548886 -0.03592169 -0.04380827 -0.03811025 -0.04731432\n",
      "   -0.00550474 -0.02236625  0.0459923 ]\n",
      "  [ 0.03480581  0.01236982 -0.00646875 -0.03116666 -0.04103081\n",
      "    0.0468041   0.04265824 -0.01098816]\n",
      "  [-0.04863527 -0.01664423  0.03288651 -0.01750059  0.00012063\n",
      "    0.00699423 -0.02460462 -0.01855447]\n",
      "  [-0.02570124  0.03301226  0.00364808 -0.03380039  0.03013071\n",
      "    0.03675773  0.00792041 -0.04911968]]\n",
      "\n",
      " [[-0.00548886 -0.03592169 -0.04380827 -0.03811025 -0.04731432\n",
      "   -0.00550474 -0.02236625  0.0459923 ]\n",
      "  [ 0.02352202  0.01905927  0.02116759 -0.04492472  0.00114735\n",
      "   -0.01074374 -0.03446828  0.04657385]\n",
      "  [-0.00521493 -0.02499979  0.0411833  -0.04705396 -0.03437755\n",
      "   -0.03328681  0.04742551 -0.04182632]\n",
      "  [-0.0319088  -0.03847919  0.00867068 -0.03605264 -0.04605315\n",
      "    0.02373978 -0.01911396 -0.03347591]]\n",
      "\n",
      " [[-0.00548886 -0.03592169 -0.04380827 -0.03811025 -0.04731432\n",
      "   -0.00550474 -0.02236625  0.0459923 ]\n",
      "  [-0.00521493 -0.02499979  0.0411833  -0.04705396 -0.03437755\n",
      "   -0.03328681  0.04742551 -0.04182632]\n",
      "  [-0.00184004 -0.03448504  0.02520813  0.0427362   0.02878145\n",
      "   -0.02024512 -0.02827085  0.04391212]\n",
      "  [-0.02570124  0.03301226  0.00364808 -0.03380039  0.03013071\n",
      "    0.03675773  0.00792041 -0.04911968]]\n",
      "\n",
      " [[-0.00548886 -0.03592169 -0.04380827 -0.03811025 -0.04731432\n",
      "   -0.00550474 -0.02236625  0.0459923 ]\n",
      "  [-0.00521493 -0.02499979  0.0411833  -0.04705396 -0.03437755\n",
      "   -0.03328681  0.04742551 -0.04182632]\n",
      "  [-0.04863527 -0.01664423  0.03288651 -0.01750059  0.00012063\n",
      "    0.00699423 -0.02460462 -0.01855447]\n",
      "  [-0.02570124  0.03301226  0.00364808 -0.03380039  0.03013071\n",
      "    0.03675773  0.00792041 -0.04911968]]]\n"
     ]
    }
   ],
   "source": [
    "embeddings=embeddings.reshape(-1,maxlen,8)\n",
    "print(\"Shape of embeddings : \",embeddings.shape) \n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O enconding para a palavra 1 no documento 1 é: \n",
      "\n",
      " [-0.00548886 -0.03592169 -0.04380827 -0.03811025 -0.04731432 -0.00550474\n",
      " -0.02236625  0.0459923 ]\n",
      "O enconding para a palavra 2 no documento 1 é: \n",
      "\n",
      " [ 0.04638492 -0.00064833 -0.0301376   0.0405165   0.01600995  0.029288\n",
      " -0.02455816  0.04661772]\n",
      "O enconding para a palavra 3 no documento 1 é: \n",
      "\n",
      " [-0.00184004 -0.03448504  0.02520813  0.0427362   0.02878145 -0.02024512\n",
      " -0.02827085  0.04391212]\n",
      "O enconding para a palavra 4 no documento 1 é: \n",
      "\n",
      " [-0.02570124  0.03301226  0.00364808 -0.03380039  0.03013071  0.03675773\n",
      "  0.00792041 -0.04911968]\n",
      "O enconding para a palavra 1 no documento 2 é: \n",
      "\n",
      " [-0.00548886 -0.03592169 -0.04380827 -0.03811025 -0.04731432 -0.00550474\n",
      " -0.02236625  0.0459923 ]\n",
      "O enconding para a palavra 2 no documento 2 é: \n",
      "\n",
      " [ 0.04638492 -0.00064833 -0.0301376   0.0405165   0.01600995  0.029288\n",
      " -0.02455816  0.04661772]\n",
      "O enconding para a palavra 3 no documento 2 é: \n",
      "\n",
      " [-0.04863527 -0.01664423  0.03288651 -0.01750059  0.00012063  0.00699423\n",
      " -0.02460462 -0.01855447]\n",
      "O enconding para a palavra 4 no documento 2 é: \n",
      "\n",
      " [-0.02570124  0.03301226  0.00364808 -0.03380039  0.03013071  0.03675773\n",
      "  0.00792041 -0.04911968]\n",
      "O enconding para a palavra 1 no documento 3 é: \n",
      "\n",
      " [-0.00548886 -0.03592169 -0.04380827 -0.03811025 -0.04731432 -0.00550474\n",
      " -0.02236625  0.0459923 ]\n",
      "O enconding para a palavra 2 no documento 3 é: \n",
      "\n",
      " [ 0.03480581  0.01236982 -0.00646875 -0.03116666 -0.04103081  0.0468041\n",
      "  0.04265824 -0.01098816]\n",
      "O enconding para a palavra 3 no documento 3 é: \n",
      "\n",
      " [-0.0319088  -0.03847919  0.00867068 -0.03605264 -0.04605315  0.02373978\n",
      " -0.01911396 -0.03347591]\n",
      "O enconding para a palavra 4 no documento 3 é: \n",
      "\n",
      " [-0.02570124  0.03301226  0.00364808 -0.03380039  0.03013071  0.03675773\n",
      "  0.00792041 -0.04911968]\n",
      "O enconding para a palavra 1 no documento 4 é: \n",
      "\n",
      " [-0.00548886 -0.03592169 -0.04380827 -0.03811025 -0.04731432 -0.00550474\n",
      " -0.02236625  0.0459923 ]\n",
      "O enconding para a palavra 2 no documento 4 é: \n",
      "\n",
      " [ 0.03480581  0.01236982 -0.00646875 -0.03116666 -0.04103081  0.0468041\n",
      "  0.04265824 -0.01098816]\n",
      "O enconding para a palavra 3 no documento 4 é: \n",
      "\n",
      " [-0.00184004 -0.03448504  0.02520813  0.0427362   0.02878145 -0.02024512\n",
      " -0.02827085  0.04391212]\n",
      "O enconding para a palavra 4 no documento 4 é: \n",
      "\n",
      " [-0.02570124  0.03301226  0.00364808 -0.03380039  0.03013071  0.03675773\n",
      "  0.00792041 -0.04911968]\n",
      "O enconding para a palavra 1 no documento 5 é: \n",
      "\n",
      " [-0.00548886 -0.03592169 -0.04380827 -0.03811025 -0.04731432 -0.00550474\n",
      " -0.02236625  0.0459923 ]\n",
      "O enconding para a palavra 2 no documento 5 é: \n",
      "\n",
      " [ 0.03480581  0.01236982 -0.00646875 -0.03116666 -0.04103081  0.0468041\n",
      "  0.04265824 -0.01098816]\n",
      "O enconding para a palavra 3 no documento 5 é: \n",
      "\n",
      " [-0.04863527 -0.01664423  0.03288651 -0.01750059  0.00012063  0.00699423\n",
      " -0.02460462 -0.01855447]\n",
      "O enconding para a palavra 4 no documento 5 é: \n",
      "\n",
      " [-0.02570124  0.03301226  0.00364808 -0.03380039  0.03013071  0.03675773\n",
      "  0.00792041 -0.04911968]\n",
      "O enconding para a palavra 1 no documento 6 é: \n",
      "\n",
      " [-0.00548886 -0.03592169 -0.04380827 -0.03811025 -0.04731432 -0.00550474\n",
      " -0.02236625  0.0459923 ]\n",
      "O enconding para a palavra 2 no documento 6 é: \n",
      "\n",
      " [ 0.02352202  0.01905927  0.02116759 -0.04492472  0.00114735 -0.01074374\n",
      " -0.03446828  0.04657385]\n",
      "O enconding para a palavra 3 no documento 6 é: \n",
      "\n",
      " [-0.00521493 -0.02499979  0.0411833  -0.04705396 -0.03437755 -0.03328681\n",
      "  0.04742551 -0.04182632]\n",
      "O enconding para a palavra 4 no documento 6 é: \n",
      "\n",
      " [-0.0319088  -0.03847919  0.00867068 -0.03605264 -0.04605315  0.02373978\n",
      " -0.01911396 -0.03347591]\n",
      "O enconding para a palavra 1 no documento 7 é: \n",
      "\n",
      " [-0.00548886 -0.03592169 -0.04380827 -0.03811025 -0.04731432 -0.00550474\n",
      " -0.02236625  0.0459923 ]\n",
      "O enconding para a palavra 2 no documento 7 é: \n",
      "\n",
      " [-0.00521493 -0.02499979  0.0411833  -0.04705396 -0.03437755 -0.03328681\n",
      "  0.04742551 -0.04182632]\n",
      "O enconding para a palavra 3 no documento 7 é: \n",
      "\n",
      " [-0.00184004 -0.03448504  0.02520813  0.0427362   0.02878145 -0.02024512\n",
      " -0.02827085  0.04391212]\n",
      "O enconding para a palavra 4 no documento 7 é: \n",
      "\n",
      " [-0.02570124  0.03301226  0.00364808 -0.03380039  0.03013071  0.03675773\n",
      "  0.00792041 -0.04911968]\n",
      "O enconding para a palavra 1 no documento 8 é: \n",
      "\n",
      " [-0.00548886 -0.03592169 -0.04380827 -0.03811025 -0.04731432 -0.00550474\n",
      " -0.02236625  0.0459923 ]\n",
      "O enconding para a palavra 2 no documento 8 é: \n",
      "\n",
      " [-0.00521493 -0.02499979  0.0411833  -0.04705396 -0.03437755 -0.03328681\n",
      "  0.04742551 -0.04182632]\n",
      "O enconding para a palavra 3 no documento 8 é: \n",
      "\n",
      " [-0.04863527 -0.01664423  0.03288651 -0.01750059  0.00012063  0.00699423\n",
      " -0.02460462 -0.01855447]\n",
      "O enconding para a palavra 4 no documento 8 é: \n",
      "\n",
      " [-0.02570124  0.03301226  0.00364808 -0.03380039  0.03013071  0.03675773\n",
      "  0.00792041 -0.04911968]\n"
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate(embeddings):\n",
    "    for j, word in enumerate(doc):\n",
    "        print(\"O enconding para a palavra\", j + 1, \"no documento\", i + 1,\"é: \\n\\n\", word)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
